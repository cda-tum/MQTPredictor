{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5189fbc1",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49eeb4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data loading failed.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/f4/n3_mnvbd6q50h0gtzy84vyn40000gn/T/ipykernel_7004/16218107.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel_selection\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtrain_test_split\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m \u001B[0mtraining_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnames_list\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscores_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_training_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mtraining_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from mqt.predictor.driver import Predictor\n",
    "from mqt.predictor import utils\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_data, names_list, scores_list = utils.load_training_data()\n",
    "X, y = zip(*training_data)\n",
    "X = list(X)\n",
    "y = list(y)\n",
    "for i in range(len(X)):\n",
    "    X[i] = list(X[i])\n",
    "    scores_list[i] = list(scores_list[i])\n",
    "\n",
    "\n",
    "X, y, indices = np.array(X), np.array(y), np.array(range(len(y)))\n",
    "\n",
    "non_zero_indices = []\n",
    "for i in range(len(X[0])):\n",
    "    if sum(X[:, i]) > 0:\n",
    "        non_zero_indices.append(i)\n",
    "X = X[:, non_zero_indices]\n",
    "data = asarray(non_zero_indices)\n",
    "save(\"non_zero_indices.npy\", data)\n",
    "\n",
    "(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    indices_train,\n",
    "    indices_test,\n",
    ") = train_test_split(X, y, indices, test_size=0.3, random_state=5)\n",
    "\n",
    "scores_filtered = [scores_list[i] for i in indices_test]\n",
    "names_filtered = [names_list[i] for i in indices_test]\n",
    "\n",
    "predictor = Predictor()\n",
    "performance = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b453a219",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e277b733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "tree_param = [\n",
    "    {\n",
    "        \"n_estimators\": [100, 200, 500],\n",
    "        \"max_features\": [\"auto\", \"sqrt\"],\n",
    "        \"max_depth\": list(range(8, 30, 6)),\n",
    "        \"min_samples_split\": list(range(2, 20, 6)),\n",
    "        \"min_samples_leaf\": list(range(2, 20, 6)),\n",
    "        \"bootstrap\": [True, False],\n",
    "    },\n",
    "]\n",
    "\n",
    "clf = GridSearchCV(clf, tree_param, cv=5, n_jobs=8).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = np.array(list(clf.predict(X_test)))\n",
    "res = predictor.plot_eval_histogram(\n",
    "    scores_filtered, y_pred, y_test, filename=\"RandomForestClassifier\"\n",
    ")\n",
    "\n",
    "print(\"Best Accuracy: \", clf.best_score_)\n",
    "top3 = (res.count(1) + res.count(2) + res.count(3)) / len(res)\n",
    "print(\"Top 3: \", top3)\n",
    "print(\"Feature Importance: \", clf.best_estimator_.feature_importances_)\n",
    "performance.append((\"RandomForestClassifier\", clf.best_score_, top3, max(res)))\n",
    "\n",
    "predictor.set_classifier(clf.best_estimator_)\n",
    "utils.save_classifier(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab679fa",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cbaebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "openqasm_qc_list = utils.get_openqasm_gates()\n",
    "feature_names = [openqasm_qc_list[i] for i in range(0, len(openqasm_qc_list))]\n",
    "feature_names.append(\"num_qubits\")\n",
    "feature_names.append(\"depth\")\n",
    "feature_names.append(\"program_communication\")\n",
    "feature_names.append(\"critical_depth\")\n",
    "feature_names.append(\"entanglement_ratio\")\n",
    "feature_names.append(\"parallelism\")\n",
    "feature_names.append(\"liveness\")\n",
    "feature_names = [feature_names[i] for i in non_zero_indices]\n",
    "\n",
    "importances = clf.best_estimator_.feature_importances_\n",
    "std = np.std(\n",
    "    [tree.feature_importances_ for tree in clf.best_estimator_.estimators_], axis=0\n",
    ")\n",
    "\n",
    "idx = np.argsort(-importances)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.bar(np.array(feature_names)[idx], np.array(importances)[idx])\n",
    "plt.errorbar(\n",
    "    np.array(feature_names)[idx],\n",
    "    np.array(importances)[idx],\n",
    "    np.array(std)[idx],\n",
    "    fmt=\"o\",\n",
    "    color=\"lightgreen\",\n",
    ")\n",
    "plt.xticks(rotation=90, fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.ylabel(\"Relative feature importance\", fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"mqt/predictor/results/feature_importances.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42c42e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictor.plot_eval_all_detailed_compact_normed(\n",
    "    names_filtered, scores_filtered, y_pred, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4253d80e",
   "metadata": {},
   "source": [
    "# GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aca3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.01, 0.1, 1],\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(clf, param_grid, cv=5, n_jobs=8).fit(X_train, y_train)\n",
    "\n",
    "y_pred = np.array(list(clf.predict(X_test)))\n",
    "res = predictor.plot_eval_histogram(\n",
    "    scores_filtered, y_pred, y_test, filename=\"GradientBoostingClassifier\"\n",
    ")\n",
    "\n",
    "print(\"Best Accuracy: \", clf.best_score_)\n",
    "top3 = (res.count(1) + res.count(2) + res.count(3)) / len(res)\n",
    "print(\"Top 3: \", top3)\n",
    "performance.append((\"GradientBoostingClassifier\", clf.best_score_, top3, max(res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e9aacd",
   "metadata": {},
   "source": [
    "# Current Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf6af73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.train_decision_tree_classifier(X, y, names_list, scores_list);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f88a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(random_state=5)\n",
    "\n",
    "tree_param = [\n",
    "    {\n",
    "        \"criterion\": [\"entropy\", \"gini\"],\n",
    "        \"max_depth\": list(range(1, 15, 1)),\n",
    "        \"min_samples_split\": list(range(2, 20, 4)),\n",
    "        \"min_samples_leaf\": list(range(2, 20, 4)),\n",
    "        \"max_leaf_nodes\": list(range(2, 200, 40)),\n",
    "        \"max_features\": list(range(1, len(non_zero_indices), 10)),\n",
    "    },\n",
    "]\n",
    "clf = GridSearchCV(clf, tree_param, cv=5, n_jobs=8).fit(X_train, y_train)\n",
    "y_pred = np.array(list(clf.predict(X_test)))\n",
    "res = predictor.plot_eval_histogram(\n",
    "    scores_filtered, y_pred, y_test, filename=\"DecisionTreeClassifier\"\n",
    ")\n",
    "\n",
    "print(\"Best Accuracy: \", clf.best_score_)\n",
    "top3 = (res.count(1) + res.count(2) + res.count(3)) / len(res)\n",
    "print(\"Top 3: \", top3)\n",
    "print(\"Feature Importance: \", clf.best_estimator_.feature_importances_)\n",
    "performance.append((\"DecisionTreeClassifier\", clf.best_score_, top3, max(res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0b7f2a",
   "metadata": {},
   "source": [
    "# Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257a9f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "param_grid = dict(n_neighbors=range(1, 10, 1))\n",
    "clf = GridSearchCV(clf, param_grid, cv=5, n_jobs=8).fit(X_train, y_train)\n",
    "\n",
    "y_pred = np.array(list(clf.predict(X_test)))\n",
    "res = predictor.plot_eval_histogram(\n",
    "    scores_filtered, y_pred, y_test, filename=\"KNeighborsClassifier\"\n",
    ")\n",
    "\n",
    "print(\"Best Accuracy: \", clf.best_score_)\n",
    "top3 = (res.count(1) + res.count(2) + res.count(3)) / len(res)\n",
    "print((\"Top 3: \", top3))\n",
    "performance.append((\"KNeighborsClassifier\", clf.best_score_, top3, max(res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769e7f1a",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb259b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC()\n",
    "param_grid = {\"C\": [0.1, 1, 10], \"gamma\": [1, 0.1, 0.01], \"kernel\": [\"rbf\", \"sigmoid\"]}\n",
    "clf = GridSearchCV(clf, param_grid, cv=5, n_jobs=8).fit(X_train, y_train)\n",
    "\n",
    "y_pred = np.array(list(clf.predict(X_test)))\n",
    "res = predictor.plot_eval_histogram(scores_filtered, y_pred, y_test, filename=\"SVM\")\n",
    "\n",
    "print(\"Best Accuracy: \", clf.best_score_)\n",
    "top3 = (res.count(1) + res.count(2) + res.count(3)) / len(res)\n",
    "print(\"Top 3: \", top3)\n",
    "performance.append((\"SVM\", clf.best_score_, top3, max(res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbac0a1",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04146e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "param_grid = {\"var_smoothing\": np.logspace(0, -9, num=100)}\n",
    "clf = GridSearchCV(clf, param_grid, cv=5, n_jobs=8).fit(X_train, y_train)\n",
    "\n",
    "y_pred = np.array(list(clf.predict(X_test)))\n",
    "res = predictor.plot_eval_histogram(\n",
    "    scores_filtered, y_pred, y_test, filename=\"GaussianNB\"\n",
    ")\n",
    "\n",
    "print(\"Best Accuracy: \", clf.best_score_)\n",
    "top3 = (res.count(1) + res.count(2) + res.count(3)) / len(res)\n",
    "print(\"Top 3: \", top3)\n",
    "performance.append((\"GaussianNB\", clf.best_score_, top3, max(res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a215cbd",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206d9158",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=200)\n",
    "\n",
    "param_grid = {\n",
    "    \"average\": [True, False],\n",
    "    \"l1_ratio\": np.linspace(0, 1, num=10),\n",
    "    \"alpha\": np.power(10, np.arange(-2, 1, dtype=float)),\n",
    "}\n",
    "clf = GridSearchCV(clf, param_grid, cv=5, n_jobs=8).fit(X_train, y_train)\n",
    "\n",
    "y_pred = np.array(list(clf.predict(X_test)))\n",
    "res = predictor.plot_eval_histogram(\n",
    "    scores_filtered, y_pred, y_test, filename=\"SGDClassifier\"\n",
    ")\n",
    "\n",
    "print(\"Best Accuracy: \", clf.best_score_)\n",
    "top3 = (res.count(1) + res.count(2) + res.count(3)) / len(res)\n",
    "print(\"Top 3: \", top3)\n",
    "performance.append((\"SGDClassifier\", clf.best_score_, top3, max(res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5ea3c3",
   "metadata": {},
   "source": [
    "# Save Performance Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e522a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(performance)\n",
    "\n",
    "filename = \"mqt/predictor/results/performances.csv\"\n",
    "with open(filename, \"w\") as f:\n",
    "    f.write(\"Algorithm, Accuracy, Top3, Worst Rank\\n\")\n",
    "    for sublist in performance:\n",
    "        line = \"{}, {}, {}, {} \\n\".format(\n",
    "            sublist[0], sublist[1], sublist[2], sublist[3]\n",
    "        )\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efc3821",
   "metadata": {},
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ae6402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from setuptools import find_namespace_packages, setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e3b7f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['src.mqt.predictor',\n",
       " 'src.mqt.predictor.training_data',\n",
       " 'src.mqt.predictor.calibration_files',\n",
       " 'src.mqt.predictor.training_samples',\n",
       " 'src.mqt.predictor.training_samples_compiled',\n",
       " 'src.mqt.predictor.results']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_namespace_packages(include=[\"src.mqt.*\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd9821b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}